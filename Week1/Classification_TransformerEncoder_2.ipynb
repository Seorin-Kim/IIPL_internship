{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm, tqdm_notebook, trange\n",
    "import sentencepiece as spm\n",
    "import wget\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext import data, datasets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26c260c3910>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 5\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "lr = 0.001\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
    "LABEL = data.Field(sequential=False, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = datasets.IMDB.splits(TEXT, LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset 구성요소 출력 : {'text': <torchtext.data.field.Field object at 0x0000026C127404F0>, 'label': <torchtext.data.field.Field object at 0x0000026C12740640>}\n",
      "testset 구성요소 출력 : {'text': <torchtext.data.field.Field object at 0x0000026C127404F0>, 'label': <torchtext.data.field.Field object at 0x0000026C12740640>}\n"
     ]
    }
   ],
   "source": [
    "print('trainset 구성요소 출력 :', trainset.fields)\n",
    "print(\"testset 구성요소 출력 :\", testset.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy.', 'it', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life,', 'such', 'as', '\"teachers\".', 'my', '35', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me', 'to', 'believe', 'that', 'bromwell', \"high's\", 'satire', 'is', 'much', 'closer', 'to', 'reality', 'than', 'is', '\"teachers\".', 'the', 'scramble', 'to', 'survive', 'financially,', 'the', 'insightful', 'students', 'who', 'can', 'see', 'right', 'through', 'their', 'pathetic', \"teachers'\", 'pomp,', 'the', 'pettiness', 'of', 'the', 'whole', 'situation,', 'all', 'remind', 'me', 'of', 'the', 'schools', 'i', 'knew', 'and', 'their', 'students.', 'when', 'i', 'saw', 'the', 'episode', 'in', 'which', 'a', 'student', 'repeatedly', 'tried', 'to', 'burn', 'down', 'the', 'school,', 'i', 'immediately', 'recalled', '.........', 'at', '..........', 'high.', 'a', 'classic', 'line:', 'inspector:', \"i'm\", 'here', 'to', 'sack', 'one', 'of', 'your', 'teachers.', 'student:', 'welcome', 'to', 'bromwell', 'high.', 'i', 'expect', 'that', 'many', 'adults', 'of', 'my', 'age', 'think', 'that', 'bromwell', 'high', 'is', 'far', 'fetched.', 'what', 'a', 'pity', 'that', 'it', \"isn't!\"]\n",
      "pos\n"
     ]
    }
   ],
   "source": [
    "print(vars(trainset[0])['text'])\n",
    "print(vars(trainset[0])['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(trainset, min_freq=5)\n",
    "LABEL.build_vocab(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 46159\n",
      "클래스의 개수 : 2\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "n_classes = 2\n",
    "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
    "print('클래스의 개수 : {}'.format(n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, valset = trainset.split(split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = data.BucketIterator.splits((trainset, valset, testset), batch_size=BATCH_SIZE, shuffle=True, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 미니 배치의 개수 : 313\n",
      "테스트 데이터의 미니 배치의 개수 : 391\n",
      "검증 데이터의 미니 배치의 개수 : 79\n"
     ]
    }
   ],
   "source": [
    "print('훈련 데이터의 미니 배치의 개수 : {}'.format(len(train_iter)))\n",
    "print('테스트 데이터의 미니 배치의 개수 : {}'.format(len(test_iter)))\n",
    "print('검증 데이터의 미니 배치의 개수 : {}'.format(len(val_iter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 457])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(batch.text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 903])\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_iter))\n",
    "print(batch.text.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, val_iter, test_iter = data.BucketIterator.splits((trainset,valset,testset), batch_size=BATCH_SIZE, shuffle=True, repeat=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "* reference    \n",
    "http://nlp.seas.harvard.edu/2018/04/03/attention.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        mask = mask.squeeze(3)\n",
    "        mask = mask.reshape(-1,1,1,64)\n",
    "        #scores = scores.reshape(64,64,8,-1)\n",
    "\n",
    "        print('attention func mask.size():', mask.size())\n",
    "        print('attention func scores.size():', scores.size())\n",
    "\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"\n",
    "    \"\"\"   \n",
    "        \n",
    "        \n",
    "    def __init__(self, n_token, n_dim_model, n_head, n_hidden, n_blocks, src_pad_idx, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        \n",
    "        # #Multi Headed Attention Layer\n",
    "        self_attention = MultiHeadedAttention(n_head, n_dim_model)\n",
    "        # #Feedforward Layer\n",
    "        feed_forward = PositionwiseFeedForward(n_dim_model, n_hidden, dropout)\n",
    "        # #Positional Encoding\n",
    "        positional_encoding = PositionalEncoding(n_dim_model, dropout)\n",
    "        \n",
    "        encoder_layer = EncoderLayer(n_dim_model, copy.deepcopy(self_attention), copy.deepcopy(feed_forward), dropout)\n",
    "        self.encoder = Encoder(encoder_layer, n_blocks)\n",
    "\n",
    "        embedding = Embeddings(n_dim_model, n_token)\n",
    "        self.src_embed = nn.Sequential(embedding, copy.deepcopy(positional_encoding))\n",
    "        \n",
    "        # Fully-Connected Layer\n",
    "        self.fc = nn.Linear(n_dim_model, 2)\n",
    "\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "\n",
    "\n",
    "    # 소스 문장의 <pad> 토큰에 대하여 마스크(mask) 값을 0으로 설정\n",
    "    def make_src_mask(self, src):\n",
    "\n",
    "        # src: [batch_size, src_len]\n",
    "\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        # src_mask: [batch_size, 1, 1, src_len]\n",
    "\n",
    "        return src_mask\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        mask = self.make_src_mask(x)\n",
    "        print('mask.size():', mask.size())\n",
    "\n",
    "        # # x dimension[k, batch_size = 64]\n",
    "        embedded_sents = self.src_embed(x.permute(1,0))        \n",
    "        encoded_sents = self.encoder(embedded_sents, mask)\n",
    "        \n",
    "       \n",
    "        final_feature_map = encoded_sents[:,-1,:] \n",
    "        final_out = self.fc(final_feature_map) \n",
    "        \n",
    "        return final_out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "MODEL_DIM = 512\n",
    "HIDDEN_DIM = 256\n",
    "N_LAYERS = 3\n",
    "N_HEADS = 8\n",
    "DROPOUT_RATIO = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "LABEL_PAD_IDX = LABEL.vocab.stoi[LABEL.pad_token]\n",
    "\n",
    "model = TransformerModel(INPUT_DIM, MODEL_DIM, N_HEADS, HIDDEN_DIM, N_LAYERS, TEXT_PAD_IDX, DROPOUT_RATIO)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 27,582,210 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (w_2): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (w_2): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=256, bias=True)\n",
       "          (w_2): Linear(in_features=256, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (src_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(46159, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 457])\n",
      "torch.Size([64])\n",
      "mask.size(): torch.Size([64, 1, 1, 457])\n",
      "attention func mask.size(): torch.Size([457, 1, 1, 64])\n",
      "attention func scores.size(): torch.Size([457, 8, 64, 64])\n",
      "attention func mask.size(): torch.Size([457, 1, 1, 64])\n",
      "attention func scores.size(): torch.Size([457, 8, 64, 64])\n",
      "attention func mask.size(): torch.Size([457, 1, 1, 64])\n",
      "attention func scores.size(): torch.Size([457, 8, 64, 64])\n",
      "tensor([[ 3.9384e-01, -2.5070e+00],\n",
      "        [-1.1629e+00, -1.1793e+00],\n",
      "        [-2.6935e-01, -1.8729e+00],\n",
      "        [-8.4960e-01, -2.1751e+00],\n",
      "        [-4.0258e-01, -7.4275e-01],\n",
      "        [-1.9929e+00, -1.5629e+00],\n",
      "        [ 6.7688e-02, -1.5408e+00],\n",
      "        [-4.0354e-01, -1.3634e+00],\n",
      "        [ 7.3720e-02, -7.4305e-01],\n",
      "        [-1.1819e+00, -1.2491e+00],\n",
      "        [ 4.6166e-01, -3.4956e-01],\n",
      "        [-2.4461e-01, -2.1690e+00],\n",
      "        [-3.9124e-01, -4.0864e-01],\n",
      "        [-9.3944e-01, -1.5572e+00],\n",
      "        [-9.7873e-03, -1.4567e+00],\n",
      "        [-1.0338e+00, -1.8777e+00],\n",
      "        [-2.5886e-01, -2.0668e-01],\n",
      "        [-3.4398e-02, -3.2564e+00],\n",
      "        [-7.9463e-01, -2.1316e+00],\n",
      "        [-1.2281e+00, -1.5581e+00],\n",
      "        [-1.1287e+00, -1.5286e+00],\n",
      "        [-6.5752e-02, -1.6056e+00],\n",
      "        [-7.4237e-01, -3.2229e-01],\n",
      "        [ 2.1719e-01, -2.1975e+00],\n",
      "        [-7.9999e-01, -9.8782e-01],\n",
      "        [-1.1939e+00, -2.6782e+00],\n",
      "        [-5.6037e-01, -8.2289e-01],\n",
      "        [-2.7296e-01, -1.1722e+00],\n",
      "        [-9.8260e-01, -1.2319e+00],\n",
      "        [-3.2027e-01, -1.4263e+00],\n",
      "        [-5.3386e-01, -2.2474e+00],\n",
      "        [-1.3696e+00, -1.1349e+00],\n",
      "        [-1.3822e-01, -2.0246e+00],\n",
      "        [ 4.9814e-01, -1.5752e+00],\n",
      "        [-7.7193e-01, -1.4371e+00],\n",
      "        [-4.4456e-01, -3.2175e+00],\n",
      "        [-3.2922e-01, -2.0040e+00],\n",
      "        [-4.5171e-01, -3.0091e+00],\n",
      "        [-1.3106e+00, -2.1639e+00],\n",
      "        [-6.5139e-01, -6.3069e-01],\n",
      "        [-5.9805e-01, -3.7098e-01],\n",
      "        [-1.2688e+00, -2.9803e+00],\n",
      "        [-1.3734e+00, -2.1385e+00],\n",
      "        [-3.2047e-01, -1.3089e+00],\n",
      "        [-1.3348e+00, -1.4607e+00],\n",
      "        [ 9.1889e-01, -7.4436e-01],\n",
      "        [-5.6525e-01, -2.1159e+00],\n",
      "        [-1.3667e+00, -1.8384e+00],\n",
      "        [-6.7757e-02, -2.1290e+00],\n",
      "        [-1.9198e-01, -3.4851e+00],\n",
      "        [-1.7409e-01, -2.4200e+00],\n",
      "        [-2.8524e-01, -1.9605e+00],\n",
      "        [-1.6219e+00, -1.9287e+00],\n",
      "        [-1.6788e+00, -2.8929e+00],\n",
      "        [-1.1483e+00, -1.2653e+00],\n",
      "        [-1.2076e+00, -1.8939e+00],\n",
      "        [-7.9769e-01, -1.4811e+00],\n",
      "        [-9.5402e-01, -1.2616e+00],\n",
      "        [-6.2023e-01, -1.6855e+00],\n",
      "        [-7.3797e-01, -1.7992e+00],\n",
      "        [-8.6021e-01, -1.2411e+00],\n",
      "        [-1.3069e-02, -1.6092e+00],\n",
      "        [-8.6724e-01, -7.7181e-01],\n",
      "        [-4.6818e-01, -2.8429e+00],\n",
      "        [-9.1097e-01, -1.6237e+00],\n",
      "        [-5.0184e-01, -1.9810e+00],\n",
      "        [-3.5036e-01, -1.1448e+00],\n",
      "        [-1.1552e+00, -2.1842e+00],\n",
      "        [-5.1171e-01, -1.6502e+00],\n",
      "        [-9.0521e-01, -8.8192e-01],\n",
      "        [-3.0598e-01, -2.3134e-01],\n",
      "        [-4.8538e-01, -1.7210e+00],\n",
      "        [ 5.2595e-01, -1.0971e+00],\n",
      "        [-8.2588e-01, -1.5868e+00],\n",
      "        [ 3.4310e-01,  8.5852e-01],\n",
      "        [ 6.2912e-01, -1.7045e+00],\n",
      "        [-9.8604e-01, -2.4460e+00],\n",
      "        [-9.4302e-02, -2.1426e+00],\n",
      "        [-1.1154e+00, -1.4291e+00],\n",
      "        [-2.6051e+00, -3.5026e-01],\n",
      "        [-1.2390e+00, -1.1374e+00],\n",
      "        [-1.2781e-01, -1.1494e+00],\n",
      "        [-2.6308e-01, -1.4679e+00],\n",
      "        [-3.3066e-01, -1.8380e+00],\n",
      "        [-4.2577e-01, -1.2366e+00],\n",
      "        [-1.6742e+00, -1.7380e+00],\n",
      "        [-7.7676e-01, -6.4184e-01],\n",
      "        [-6.1944e-01, -1.2323e+00],\n",
      "        [ 1.4597e-01, -1.9676e+00],\n",
      "        [-7.6382e-01, -1.8993e+00],\n",
      "        [ 5.0320e-01, -2.2541e+00],\n",
      "        [-1.0997e+00, -1.8175e+00],\n",
      "        [-8.7142e-01, -2.4042e+00],\n",
      "        [-7.9598e-01, -1.3725e+00],\n",
      "        [ 8.0839e-01, -1.3972e+00],\n",
      "        [-3.8485e-01, -1.0293e+00],\n",
      "        [-1.0940e-02, -2.3378e+00],\n",
      "        [-8.6503e-01, -1.3787e+00],\n",
      "        [-4.2647e-01, -8.3297e-01],\n",
      "        [-5.2413e-01, -1.9922e+00],\n",
      "        [-1.3010e+00, -1.9966e+00],\n",
      "        [-5.5352e-01, -1.4709e+00],\n",
      "        [ 7.0835e-01, -8.5183e-01],\n",
      "        [ 1.2860e-02, -2.2870e+00],\n",
      "        [ 6.7230e-01, -1.2553e+00],\n",
      "        [-8.0269e-01, -2.8992e+00],\n",
      "        [-6.9115e-01, -1.8231e+00],\n",
      "        [-4.8626e-01, -1.3563e+00],\n",
      "        [-8.8558e-01, -2.4678e+00],\n",
      "        [ 9.5239e-01, -6.6196e-01],\n",
      "        [-4.6143e-01, -6.7526e-01],\n",
      "        [ 5.3315e-01, -8.7023e-01],\n",
      "        [-1.7839e+00, -1.7590e+00],\n",
      "        [-4.5771e-01, -1.8798e+00],\n",
      "        [ 2.3852e-01, -1.8715e+00],\n",
      "        [-6.7454e-01, -2.7036e+00],\n",
      "        [ 1.7042e-01, -2.2977e+00],\n",
      "        [-4.4515e-01, -1.9336e+00],\n",
      "        [ 4.0165e-01, -2.2333e+00],\n",
      "        [-1.5459e+00, -1.4353e+00],\n",
      "        [-1.0929e+00, -8.9305e-01],\n",
      "        [-1.0901e+00, -1.6919e+00],\n",
      "        [-1.0554e+00, -9.9453e-01],\n",
      "        [-4.2552e-01, -1.2314e+00],\n",
      "        [-1.4416e+00, -2.0952e+00],\n",
      "        [ 2.2436e+00,  4.0634e-01],\n",
      "        [ 4.3646e-01, -1.2736e+00],\n",
      "        [-6.1848e-01, -1.6565e+00],\n",
      "        [-8.1422e-01, -1.4276e+00],\n",
      "        [ 3.9110e-01, -1.3123e+00],\n",
      "        [-2.5072e-01, -1.1608e+00],\n",
      "        [-8.3855e-01, -6.8553e-01],\n",
      "        [-4.5745e-01, -2.5940e+00],\n",
      "        [ 2.8332e-01, -1.6206e+00],\n",
      "        [ 1.2546e-01, -2.3716e+00],\n",
      "        [-1.0479e-01, -2.3937e+00],\n",
      "        [ 2.0777e-01, -1.6603e+00],\n",
      "        [-9.1728e-01, -2.0788e+00],\n",
      "        [-8.9923e-01, -1.3457e+00],\n",
      "        [ 1.6522e+00, -1.9325e+00],\n",
      "        [-1.4438e+00, -6.6700e-01],\n",
      "        [-3.6483e-01, -1.5728e+00],\n",
      "        [-9.0286e-01, -2.0735e+00],\n",
      "        [-1.6622e+00, -1.8874e+00],\n",
      "        [-3.2616e-01, -2.4605e+00],\n",
      "        [ 3.7160e-01,  4.0782e-01],\n",
      "        [-1.1834e+00, -1.4572e+00],\n",
      "        [-7.0872e-01, -2.3385e+00],\n",
      "        [-5.3851e-01, -2.1456e+00],\n",
      "        [-9.3569e-01, -1.9641e+00],\n",
      "        [-8.8139e-01, -1.5269e+00],\n",
      "        [-6.2437e-01, -2.3178e+00],\n",
      "        [ 3.5008e-01, -7.6945e-02],\n",
      "        [-3.5770e-01, -6.3802e-01],\n",
      "        [-1.3676e-01, -1.6911e+00],\n",
      "        [ 1.6404e-01, -1.5439e+00],\n",
      "        [-2.7889e-01, -1.4610e+00],\n",
      "        [-9.3708e-01, -3.0389e+00],\n",
      "        [-7.8148e-01, -2.2723e+00],\n",
      "        [-8.8589e-01, -8.7364e-01],\n",
      "        [-8.0546e-01, -1.6970e+00],\n",
      "        [-8.0234e-01, -1.2716e+00],\n",
      "        [-1.1562e+00, -1.4018e+00],\n",
      "        [ 1.8738e-01, -1.5389e+00],\n",
      "        [-1.2785e+00, -1.7929e+00],\n",
      "        [-1.7132e+00, -2.9604e+00],\n",
      "        [-7.7726e-01, -1.6793e+00],\n",
      "        [-1.4939e+00, -2.1739e+00],\n",
      "        [-3.3950e-01, -1.3981e+00],\n",
      "        [-1.1180e+00, -1.8782e+00],\n",
      "        [ 5.3924e-02, -9.8811e-01],\n",
      "        [ 6.4820e-01, -1.6039e+00],\n",
      "        [-4.7985e-01, -1.9393e+00],\n",
      "        [-3.5712e-01, -2.4978e+00],\n",
      "        [-1.8390e-01, -2.0678e+00],\n",
      "        [ 1.9979e-01, -2.4398e+00],\n",
      "        [-1.4726e-01, -1.7361e+00],\n",
      "        [-4.2641e-01, -1.6418e+00],\n",
      "        [-4.7742e-01, -2.6048e+00],\n",
      "        [-7.2690e-02, -1.5339e+00],\n",
      "        [-1.2636e-01, -1.6552e+00],\n",
      "        [ 9.4642e-02, -1.4386e+00],\n",
      "        [-7.2202e-01, -2.4608e+00],\n",
      "        [-6.8341e-01, -1.5584e+00],\n",
      "        [-9.5424e-01, -3.7636e+00],\n",
      "        [-2.6131e-01, -2.7307e+00],\n",
      "        [-5.9459e-01, -1.5308e+00],\n",
      "        [ 6.9992e-01, -4.5754e-01],\n",
      "        [-5.8023e-01, -1.1322e+00],\n",
      "        [-5.6723e-01, -2.4360e+00],\n",
      "        [-1.1433e+00, -2.0424e+00],\n",
      "        [-1.0581e+00, -1.6784e+00],\n",
      "        [-5.4370e-01, -6.2014e-01],\n",
      "        [-7.8799e-01, -1.3834e+00],\n",
      "        [ 1.9313e-01, -1.3309e+00],\n",
      "        [ 3.0504e-02, -1.3718e+00],\n",
      "        [-9.9329e-01, -1.2470e+00],\n",
      "        [ 5.0299e-01, -2.0456e+00],\n",
      "        [-8.3272e-01, -2.2697e+00],\n",
      "        [ 5.0100e-02, -2.2146e+00],\n",
      "        [-8.7699e-01, -1.1840e+00],\n",
      "        [-1.8118e-01, -2.1782e+00],\n",
      "        [-1.1849e+00, -1.3428e+00],\n",
      "        [-9.8837e-01, -2.1365e+00],\n",
      "        [-2.8539e-02, -1.4134e+00],\n",
      "        [-1.0202e+00, -1.9056e+00],\n",
      "        [-2.6185e-01, -1.6720e+00],\n",
      "        [-1.4396e+00, -1.5198e+00],\n",
      "        [-1.6823e+00, -1.8442e+00],\n",
      "        [-9.8815e-01, -1.2286e+00],\n",
      "        [-1.1371e+00, -9.5707e-01],\n",
      "        [-1.6681e+00, -1.9191e+00],\n",
      "        [-5.4819e-01, -2.3231e+00],\n",
      "        [-1.6357e-02, -1.9171e+00],\n",
      "        [-2.6078e+00, -2.2311e+00],\n",
      "        [-1.3083e+00, -2.2416e+00],\n",
      "        [ 9.9055e-01, -8.0121e-01],\n",
      "        [-3.5262e-01, -1.7699e+00],\n",
      "        [-3.3698e-01, -1.4322e+00],\n",
      "        [-6.9933e-01, -2.0079e+00],\n",
      "        [-1.4447e-01, -1.4515e+00],\n",
      "        [-9.8771e-01, -2.3224e+00],\n",
      "        [-1.9651e+00, -1.5316e+00],\n",
      "        [-5.5550e-01, -2.6230e+00],\n",
      "        [ 6.3325e-01, -1.9632e+00],\n",
      "        [-7.0793e-02, -1.6645e+00],\n",
      "        [-2.0381e-01, -1.1599e-01],\n",
      "        [-2.8482e-01, -2.1221e+00],\n",
      "        [-1.8051e+00, -1.3078e+00],\n",
      "        [-4.3269e-01, -2.3838e+00],\n",
      "        [-6.7664e-01, -1.8299e+00],\n",
      "        [-1.9542e-01, -2.2889e-01],\n",
      "        [-8.5237e-01, -2.1443e+00],\n",
      "        [-6.5337e-01, -1.4540e+00],\n",
      "        [-1.9100e-01, -1.8686e+00],\n",
      "        [-6.3154e-01, -2.0913e+00],\n",
      "        [-8.1818e-02, -1.4300e+00],\n",
      "        [-2.0531e+00, -2.6359e+00],\n",
      "        [-1.0789e+00, -2.4421e+00],\n",
      "        [-1.4964e+00, -1.6896e+00],\n",
      "        [-2.8331e-03, -2.9378e+00],\n",
      "        [-7.2381e-01, -1.9138e+00],\n",
      "        [-1.9962e-01, -1.3247e+00],\n",
      "        [-1.2827e+00, -2.0234e+00],\n",
      "        [-1.5085e+00, -1.8328e+00],\n",
      "        [ 1.3720e+00, -1.4632e+00],\n",
      "        [ 1.8613e-01, -7.3892e-01],\n",
      "        [-3.7174e-01, -1.9948e+00],\n",
      "        [ 1.5116e-01, -2.2965e+00],\n",
      "        [-5.3898e-01, -3.3244e+00],\n",
      "        [-3.1060e-01, -2.3510e+00],\n",
      "        [ 4.1587e-03, -2.1669e+00],\n",
      "        [-7.1171e-01, -9.1054e-01],\n",
      "        [-1.1172e+00, -1.9419e+00],\n",
      "        [-6.1082e-01, -6.1311e-01],\n",
      "        [-5.4247e-01, -2.4396e+00],\n",
      "        [-6.0847e-01, -2.9985e+00],\n",
      "        [ 8.7503e-02, -2.4123e+00],\n",
      "        [-7.3435e-01, -7.0731e-01],\n",
      "        [-1.2271e+00, -1.6334e+00],\n",
      "        [-1.1053e+00, -2.1478e+00],\n",
      "        [-3.8341e-01, -1.7855e+00],\n",
      "        [-9.4974e-01, -1.4095e+00],\n",
      "        [-5.6025e-01, -1.1854e+00],\n",
      "        [ 1.0326e-01, -2.0937e+00],\n",
      "        [-3.8141e-01, -2.0746e+00],\n",
      "        [ 1.3478e+00, -1.2170e+00],\n",
      "        [-6.4539e-01, -2.5341e+00],\n",
      "        [-5.8917e-01, -1.2274e+00],\n",
      "        [ 3.2922e-01, -2.0787e+00],\n",
      "        [-5.2185e-01, -2.0491e+00],\n",
      "        [-3.6366e-01, -1.3509e+00],\n",
      "        [-5.6848e-01, -2.3697e+00],\n",
      "        [-5.4454e-01, -1.0389e+00],\n",
      "        [-6.1860e-01, -1.7467e+00],\n",
      "        [-4.6124e-01, -1.5182e+00],\n",
      "        [-1.0732e+00, -2.0594e+00],\n",
      "        [ 8.3281e-01, -1.7525e+00],\n",
      "        [-1.0628e+00, -1.8358e+00],\n",
      "        [-3.7190e-01, -2.5616e+00],\n",
      "        [-1.0123e+00, -1.5491e+00],\n",
      "        [ 1.3961e-01, -1.4364e+00],\n",
      "        [ 1.0847e+00, -1.9068e+00],\n",
      "        [ 4.0264e-01, -1.5441e+00],\n",
      "        [-5.8047e-01, -1.1752e+00],\n",
      "        [-1.4721e-01, -1.2685e+00],\n",
      "        [-2.2206e-01, -1.7840e+00],\n",
      "        [ 4.5778e-02, -2.0453e+00],\n",
      "        [-7.4049e-01, -2.2864e+00],\n",
      "        [-4.2986e-01, -1.9838e+00],\n",
      "        [ 1.8922e-02, -9.2145e-01],\n",
      "        [-5.7714e-01, -1.3830e+00],\n",
      "        [-5.2670e-01, -2.9305e+00],\n",
      "        [-3.4619e-01, -1.9592e+00],\n",
      "        [-1.5631e-01, -1.0967e+00],\n",
      "        [-1.2952e+00, -1.6444e+00],\n",
      "        [-1.0405e+00, -2.4120e+00],\n",
      "        [-5.7852e-01, -2.8681e+00],\n",
      "        [-1.1682e+00, -1.2785e+00],\n",
      "        [-6.9999e-03, -3.5505e+00],\n",
      "        [-2.3498e-01, -1.5135e+00],\n",
      "        [ 1.4373e-01, -1.6089e+00],\n",
      "        [-5.0464e-01, -2.1353e+00],\n",
      "        [-6.7390e-01, -1.9133e+00],\n",
      "        [-1.5255e+00, -9.5031e-01],\n",
      "        [-9.7888e-01, -1.3541e+00],\n",
      "        [ 2.4432e-01, -2.9691e+00],\n",
      "        [-1.5654e+00, -2.4134e+00],\n",
      "        [-8.4388e-01, -2.2640e+00],\n",
      "        [-1.6676e-01, -1.1636e+00],\n",
      "        [-1.2408e+00, -1.6236e+00],\n",
      "        [-7.7817e-01, -2.2166e+00],\n",
      "        [-1.3976e+00, -1.4505e+00],\n",
      "        [-1.0659e+00, -1.7749e+00],\n",
      "        [-2.1016e+00, -1.7496e+00],\n",
      "        [-9.5945e-02, -1.9401e+00],\n",
      "        [-3.2344e-02, -2.4887e+00],\n",
      "        [ 1.7009e-01, -1.6721e+00],\n",
      "        [-1.1724e+00, -1.5101e+00],\n",
      "        [ 1.2838e-01, -1.8207e+00],\n",
      "        [-2.1715e-01, -2.6073e+00],\n",
      "        [-1.0301e+00, -3.1206e+00],\n",
      "        [-1.2848e+00, -2.2252e+00],\n",
      "        [-8.6225e-01, -7.9509e-01],\n",
      "        [-7.8250e-01, -1.4267e+00],\n",
      "        [-5.4310e-01, -1.3400e+00],\n",
      "        [-8.1185e-02, -1.5338e+00],\n",
      "        [-7.2199e-01, -1.0635e+00],\n",
      "        [-2.2568e+00, -2.4046e+00],\n",
      "        [ 3.1490e-01, -7.7431e-01],\n",
      "        [-8.2137e-01, -1.9121e+00],\n",
      "        [-9.2618e-01, -2.4453e+00],\n",
      "        [-1.7710e+00, -1.2123e+00],\n",
      "        [ 1.4710e-01, -1.3069e+00],\n",
      "        [-1.9326e-02, -1.8214e+00],\n",
      "        [-5.2681e-01, -2.9380e+00],\n",
      "        [-1.1982e+00, -1.8061e+00],\n",
      "        [-2.3059e+00, -2.4345e+00],\n",
      "        [-5.8102e-01, -7.4216e-01],\n",
      "        [ 1.7920e+00, -1.5717e+00],\n",
      "        [-4.1011e-02, -1.5501e+00],\n",
      "        [-8.0292e-01, -1.6113e+00],\n",
      "        [-5.4887e-01, -1.9493e+00],\n",
      "        [-1.0019e+00, -1.3996e+00],\n",
      "        [-1.1000e+00, -2.7976e+00],\n",
      "        [-3.2732e-01, -1.4846e+00],\n",
      "        [-1.7552e-01, -2.8028e+00],\n",
      "        [-4.7740e-01, -2.3503e+00],\n",
      "        [-1.1689e+00, -2.4357e+00],\n",
      "        [-6.9519e-01, -1.3564e+00],\n",
      "        [-1.6063e+00, -9.4237e-01],\n",
      "        [-1.2779e+00, -1.0788e+00],\n",
      "        [-1.3015e+00, -2.3671e+00],\n",
      "        [-6.1944e-01, -2.7055e+00],\n",
      "        [ 1.2470e-01, -4.5310e-01],\n",
      "        [-9.5132e-01, -1.7560e+00],\n",
      "        [-7.8945e-01, -1.0258e+00],\n",
      "        [-2.3771e+00, -1.4304e+00],\n",
      "        [-1.4174e+00, -1.5642e+00],\n",
      "        [-7.5029e-01, -2.1068e+00],\n",
      "        [-6.1898e-01, -2.4659e+00],\n",
      "        [-9.0004e-01, -2.5252e+00],\n",
      "        [-1.1784e-01, -2.1145e+00],\n",
      "        [-1.0450e+00, -2.3481e+00],\n",
      "        [-1.0793e+00, -2.4061e+00],\n",
      "        [-3.4501e-01, -2.6952e+00],\n",
      "        [-2.3997e-01, -2.5313e+00],\n",
      "        [-5.3916e-01, -2.0032e+00],\n",
      "        [-1.1057e+00, -1.8385e+00],\n",
      "        [-6.6617e-01, -2.1299e+00],\n",
      "        [-3.0188e-01, -2.4181e+00],\n",
      "        [-8.2507e-01, -2.0911e+00],\n",
      "        [-4.5803e-01, -1.5108e+00],\n",
      "        [-5.7990e-01, -2.9981e+00],\n",
      "        [ 7.1144e-02, -2.0923e+00],\n",
      "        [-2.7387e-01, -2.6633e+00],\n",
      "        [-1.1200e+00, -2.0584e+00],\n",
      "        [ 2.0245e+00, -1.7781e+00],\n",
      "        [-1.2420e+00, -1.8323e+00],\n",
      "        [ 4.2269e-01, -2.7174e+00],\n",
      "        [-3.5695e-01, -1.7481e+00],\n",
      "        [-5.1403e-01, -1.6166e+00],\n",
      "        [-5.1448e-01, -1.6667e+00],\n",
      "        [ 4.1280e-01, -1.0165e+00],\n",
      "        [-1.1442e+00, -2.1508e+00],\n",
      "        [-7.6474e-01, -1.7740e+00],\n",
      "        [-1.0031e+00, -1.2498e+00],\n",
      "        [-4.1161e-01, -1.2420e+00],\n",
      "        [-9.8105e-01, -2.2982e+00],\n",
      "        [-1.1412e+00, -1.2382e+00],\n",
      "        [-3.4214e-01, -1.9487e+00],\n",
      "        [-1.2732e+00, -1.5036e+00],\n",
      "        [ 9.8157e-02, -2.5940e+00],\n",
      "        [-3.2648e-01, -2.1332e+00],\n",
      "        [-1.0583e+00, -1.4611e+00],\n",
      "        [-8.8792e-02, -1.4754e+00],\n",
      "        [-3.9592e-02, -2.1210e+00],\n",
      "        [-1.0177e+00, -2.2334e+00],\n",
      "        [-9.3434e-02, -6.0672e-01],\n",
      "        [-5.6324e-01, -2.7028e+00],\n",
      "        [-3.5302e-01, -1.5717e+00],\n",
      "        [-5.9070e-01, -2.1829e+00],\n",
      "        [-7.9437e-02, -3.8610e-01],\n",
      "        [-1.1265e+00, -4.5643e-01],\n",
      "        [-8.5762e-01, -2.0645e+00],\n",
      "        [-1.5697e+00, -1.9357e+00],\n",
      "        [-1.9941e+00, -1.1874e+00],\n",
      "        [-1.7329e+00, -3.1009e+00],\n",
      "        [ 6.5362e-01, -2.6932e+00],\n",
      "        [-6.0921e-01, -1.5921e+00],\n",
      "        [-1.0104e+00, -1.8929e+00],\n",
      "        [ 4.5772e-01, -1.5620e+00],\n",
      "        [-7.9524e-01, -2.2280e+00],\n",
      "        [ 2.5997e-02, -2.0459e+00],\n",
      "        [-3.8450e-01, -3.1246e+00],\n",
      "        [-5.3314e-01, -1.7676e+00],\n",
      "        [ 1.7746e-01, -2.4975e+00],\n",
      "        [ 1.4189e-01, -1.9593e+00],\n",
      "        [-1.6550e+00, -1.0495e+00],\n",
      "        [-8.0570e-01, -1.4037e+00],\n",
      "        [-3.0326e-01, -2.2803e+00],\n",
      "        [-1.4621e+00, -3.3332e+00],\n",
      "        [-5.0485e-01, -1.9772e+00],\n",
      "        [-8.8225e-01, -2.1920e+00],\n",
      "        [-6.1448e-01, -2.0191e+00],\n",
      "        [-1.1043e+00, -2.2073e+00],\n",
      "        [-9.5152e-01, -2.2008e+00],\n",
      "        [-1.6676e+00, -1.4182e+00],\n",
      "        [-1.6538e+00, -2.7048e+00],\n",
      "        [-7.9075e-01, -2.0868e+00],\n",
      "        [ 3.1875e-01, -2.6105e+00],\n",
      "        [-6.7075e-01, -1.5473e+00],\n",
      "        [ 5.7322e-01, -2.7288e+00],\n",
      "        [-4.3700e-01, -2.1173e+00],\n",
      "        [ 3.9775e-01, -2.2691e+00],\n",
      "        [-9.8041e-01, -1.5920e+00],\n",
      "        [-8.8218e-01, -1.4571e+00],\n",
      "        [-5.4116e-01, -2.2146e+00],\n",
      "        [-8.4258e-01, -1.8964e+00],\n",
      "        [-1.7606e+00, -1.8815e+00],\n",
      "        [-1.9100e+00, -1.8492e+00],\n",
      "        [-7.3994e-01, -1.3316e+00],\n",
      "        [-7.1362e-01, -3.1764e+00],\n",
      "        [-7.9882e-01, -8.1365e-01],\n",
      "        [ 4.2978e-01, -1.2630e+00],\n",
      "        [-3.9737e-01, -2.3828e+00],\n",
      "        [-1.8048e+00, -2.9733e+00],\n",
      "        [ 4.6087e-01, -2.2062e+00],\n",
      "        [-3.6387e-01, -9.3423e-01],\n",
      "        [-5.6098e-01, -2.3765e+00],\n",
      "        [-1.0872e+00, -9.4209e-01],\n",
      "        [-6.4618e-01, -1.4118e+00],\n",
      "        [-8.3942e-01, -2.7310e+00],\n",
      "        [-2.8693e-01, -2.3702e+00],\n",
      "        [-3.6640e-01, -8.6105e-01],\n",
      "        [-7.5930e-01, -3.2954e+00],\n",
      "        [-8.6615e-01, -1.1962e+00]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([457, 2])\n"
     ]
    }
   ],
   "source": [
    "for b, batch in enumerate(train_iter):\n",
    "    x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "    y.data.sub_(1)\n",
    "    print(x.size())\n",
    "    print(y.size())\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    logit = model(x)\n",
    "    print(logit)\n",
    "    print(logit.size())\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, train_iter):\n",
    "    model.train()\n",
    "    for b, batch in enumerate(train_iter):\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y.data.sub_(1)  # 레이블 값을 0과 1로 변환\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logit = model(x)\n",
    "        loss = criterion(logit, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, val_iter):\n",
    "    \"\"\"evaluate model\"\"\"\n",
    "    model.eval()\n",
    "    corrects, total_loss = 0, 0\n",
    "    for batch in val_iter:\n",
    "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
    "        y.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
    "        logit = model(x)\n",
    "        loss = criterion(logit, y, reduction='sum')\n",
    "        total_loss += loss.item()\n",
    "        corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()\n",
    "    size = len(val_iter.dataset)\n",
    "    avg_loss = total_loss / size\n",
    "    avg_accuracy = 100.0 * corrects / size\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TransformerModel' object has no attribute 'src_pad_idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\IIPL_internship\\Week1\\Classification_TransformerEncoder_2.ipynb 셀 39\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m best_val_loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, EPOCHS\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     train(model, optimizer, criterion, train_iter)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     val_loss, val_accuracy \u001b[39m=\u001b[39m evaluate(model, criterion, val_iter)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[Epoch: \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m] val loss : \u001b[39m\u001b[39m%5.2f\u001b[39;00m\u001b[39m | val accuracy : \u001b[39m\u001b[39m%5.2f\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (e, val_loss, val_accuracy))\n",
      "\u001b[1;32md:\\IIPL_internship\\Week1\\Classification_TransformerEncoder_2.ipynb 셀 39\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer, criterion, train_iter)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m y\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39msub_(\u001b[39m1\u001b[39m)  \u001b[39m# 레이블 값을 0과 1로 변환\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m logit \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(logit, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32md:\\IIPL_internship\\Week1\\Classification_TransformerEncoder_2.ipynb 셀 39\u001b[0m in \u001b[0;36mTransformerModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_src_mask(x)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     \u001b[39m# # x dimension[k, batch_size = 64]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     embedded_sents \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msrc_embed(x\u001b[39m.\u001b[39mpermute(\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m))        \n",
      "\u001b[1;32md:\\IIPL_internship\\Week1\\Classification_TransformerEncoder_2.ipynb 셀 39\u001b[0m in \u001b[0;36mTransformerModel.make_src_mask\u001b[1;34m(self, src)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_src_mask\u001b[39m(\u001b[39mself\u001b[39m, src):\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     \u001b[39m# src: [batch_size, src_len]\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     src_mask \u001b[39m=\u001b[39m (src \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msrc_pad_idx)\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     \u001b[39m# src_mask: [batch_size, 1, 1, src_len]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/IIPL_internship/Week1/Classification_TransformerEncoder_2.ipynb#X53sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m src_mask\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1207\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1205\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[0;32m   1206\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1207\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1208\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TransformerModel' object has no attribute 'src_pad_idx'"
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "for e in range(1, EPOCHS+1):\n",
    "    train(model, optimizer, criterion, train_iter)\n",
    "    val_loss, val_accuracy = evaluate(model, criterion, val_iter)\n",
    "\n",
    "    print(\"[Epoch: %d] val loss : %5.2f | val accuracy : %5.2f\" % (e, val_loss, val_accuracy))\n",
    "\n",
    "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        if not os.path.isdir(\"snapshot\"):\n",
    "            os.makedirs(\"snapshot\")\n",
    "        torch.save(model.state_dict(), 'D:/IIPL_internship/Week1/txtclassification.pt')\n",
    "        best_val_loss = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9c1d5a056f04d97314a9f946bc8c5185004572d3d68312220c0ba298420421f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
